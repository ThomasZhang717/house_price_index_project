---
title: "model_index"
author: "Zhuoran"
date: "6/7/2021"
output: html_document
---

```{r}
library(dplyr)
library(tidyr)
library(stringr)
library(foreign)
library(lubridate)
library(caret)
library(ranger)
library(gbm)
library(pdp)
library(iml)
library(solitude)
library(ggplot2)
library(isotree)
library(rpart)
library(plotly)
```


#preparation
```{r}
#after iforest
#model_expert = read.csv("./finaldatasetformodel.csv")[-1]
#no iforest detection
#model_expert = read.csv("./finaldatasetformodel_noiso.csv")[-1]

#model_expert = zzr_zscore[which(zzr_zscore$anomaly_score<=0.5),]
model_expert = zzr_zscore

model_expert$d_pool = 0
model_expert$d_pool[which(model_expert$POOL == "B/G  ")] = 1
model_expert$d_pool[which(model_expert$POOL == "A/G  ")] = 1

model_expert$d_tile = 0
model_expert$d_tile[which(model_expert$ROOF == "TILE  ")] = 1

model_expert$d_brick = 0
model_expert$d_brick[which(model_expert$WALL == "BRICK ")] = 1

model_expert$LA_DESC = as.factor(model_expert$LA_DESC)
model_expert$PROP_CLA = as.factor(model_expert$PROP_CLA)
model_expert$logprice = log(model_expert$SALE1)
model_expert$age = model_expert$year - model_expert$YEAR_BUI

#abs = read.csv("./abs_index.csv")[-1]

#data set split
set.seed(717)
temp_list = createDataPartition(model_expert$X, p = 0.7)
temp_model = model_expert[temp_list$Resample1,] #train
temp_model_test = model_expert[-temp_list$Resample1,]

set.seed(717)
temp_list = createDataPartition(temp_model_test$X, p = 0.5)
temp_model_test_combine = temp_model_test[temp_list$Resample1,] #combine
temp_model_test_compare = temp_model_test[-temp_list$Resample1,] #compare


#save partitions
#write.csv(temp_model, "./training_2015_2020q3.csv")
#write.csv(temp_model_test_combine, "./combining_2015_2020q3.csv")
#write.csv(temp_model_test_compare, "./comparing_2015_2020q3.csv")

write.csv(model_expert, "./fullsample_2015_2020q3_162237_cleanpriceonly.csv")
write.csv(temp_model, "./training_2015_2020q3_159699.csv")
write.csv(temp_model_test_combine, "./combining_2015_2020q3_159699.csv")
write.csv(temp_model_test_compare, "./comparing_2015_2020q3_159699.csv")
```


#pool gbm
```{r}

set.seed(717)
temp_list = createDataPartition(model_expert$X, p = 0.8)
temp_model = model_expert[temp_list$Resample1,]
temp_model_test = model_expert[-temp_list$Resample1,]

temp_boost = temp_model
temp_boost_test = temp_model_test


boost_test = gbm(logprice ~ quarter_num + LAND_ARE + AREA_HSE + YEAR_BUI + BEDS + BATHS + DINING + KITCHEN + FAMILY + STUDY + GAMES + LOUNGE + MEALS + cars + LA_DESC + PROP_CLA + centlong + centlat + d_pool, data = temp_boost, distribution = "gaussian", n.trees = 1500, interaction.depth = 12, shrinkage = 0.1)
#0.1 is better 48 depth is bettter 1500-2500 is better
#1000 trees, 16 depth, 0.1 rate, rmse 0.2657
#1000 trees, 8 depth, 0.1 rate, rmse 0.2704
#1500 trees, 20 depth, 0.1 rate, rmse 0.2571
#1500 trees, 32 depth, 0.1 rate, rmse 0.2515
#1500 trees, 20 depth, 0.01 rate, rmse 0.2785
#1500 trees, 32 depth, 0.01 rate, rmse 0.2735
#2500 trees, 20 depth, 0.1 rate, rmse 0.2511
#1500 trees, 48 depth, 0.1 rate, rmse 0.2456 0.2621 looks good
#1500 trees, 48 depth, 0.01 rate, rmse 0.2694
#2500 trees, 48 depth, 0.1 rate, rmse 0.2376 0.2622 better but no big diff
#2500 trees, 16 depth, 0.1 rate, rmse 0.2546 0.2632
#2500 trees, 12 depth, 0.1 rate, rmse 0.2585 0.2644

set.seed(717)
temp_pd_impute_b = partial(object = boost_test,
                         train = temp_boost[sample(1:nrow(temp_boost), replace = TRUE), ],
                         pred.var = "quarter_num",
                         n.trees = 1500,
                         pred.grid = data.frame(quarter_num = 107:max(temp_boost$quarter_num)))


pred_q_lga = data.frame(quarter_num = c(sort(rep(107:129, 29))), LA_DESC = c("ARMADALE                 ", "BASSENDEAN               ", "BAYSWATER                ", "BELMONT                  ", "CAMBRIDGE                 ", "CANNING                  ", "CLAREMONT                ", "COCKBURN                 ", "COTTESLOE                 ", "EAST FREMANTLE           ", "FREMANTLE                ", "GOSNELLS                 ", "JOONDALUP                ", "KALAMUNDA                ", "KWINANA                  ", "MELVILLE                 ", "MOSMAN PARK              ", "MUNDARING                ", "NEDLANDS                 ", "PEPPERMINT GROVE         ", "ROCKINGHAM               ", "SERPENTINE-JARRAHDALE    ", "SOUTH PERTH              ", "STIRLING                 ", "SUBIACO                  ", "SWAN                     ", "VICTORIA PARK            ", "VINCENT                  ", "WANNEROO                 "))

pred_q_class = data.frame(quarter_num = c(sort(rep(107:129, 8))), PROP_CLA = c("APARTMENT", "PLEX", "FLAT", "GROUP HOUSE", "HOME UNIT", "HOUSE", "TOWN HOUSE", "VILLA HOUSE"))

set.seed(717)
temp_pd_impute_b_lga = partial(object = boost_test,
                         train = model_expert[sample(1:nrow(model_expert), replace = TRUE), ],
                         pred.var = c("quarter_num", "LA_DESC"),
                         n.trees = 1500,
                         pred.grid = pred_q_lga)

set.seed(717)
temp_pd_impute_b_class = partial(object = boost_test,
                         train = model_expert[sample(1:nrow(model_expert), replace = TRUE), ],
                         pred.var = c("quarter_num", "PROP_CLA"),
                         n.trees = 1500,
                         pred.grid = pred_q_class)



RMSE(predict(boost_test, temp_boost_test, n.trees = 1500), temp_boost_test$logprice)
RMSE(boost_test$fit, temp_boost$logprice)

#temp_pd_impute_b$exp_diff = exp(temp_pd_impute_b$yhat - temp_pd_impute_b$yhat[34])
```


#chained gbm
```{r}
for (i in 1:128) {
  temp = temp_boost[which(temp_boost$quarter_num == i | temp_boost$quarter_num == i+1),]

  
  set.seed(717)
  boost_chain = gbm(logprice ~ quarter_num + LAND_ARE + AREA_HSE + YEAR_BUI + BEDS + BATHS + numrooms + cars + LA_DESC + PROP_CLA + centlong + centlat + d_strata + d_pool, data = temp, distribution = "gaussian", n.trees = 2500, interaction.depth = 12, shrinkage = 0.1)
  #0.1 is better, 12 depth is better, 2500 is better
  #2500 trees, 4 depth, 0.1 rate, rmse 0.191 0.228; 0.186 0.246; 0.188 0.237; 0.191 0.226; 0.192 0.225.
  #2500 trees, 6 depth, 0.1 rate, rmse 0.170 0.238; 0.171 0.237; 0.168 0.256; 0.167 0.256; 0.172 0.233.
  #2500 trees, 8 depth, 0.1 rate, rmse 0.156 0.248; 0.156 0.237; 0.157 0.236; 0.151 0.263; 0.151 0.263.
  #2500 trees, 12 depth, 0.1 rate, rmse 0.137 0.242; 0.139 0.235; 0.134 0.252; 0.134 0.246; 0.135 0.248. Best
  #2500 trees, 16 depth, 0.1 rate, rmse 0.120 0.262; 0.120 0.248; 0.117 0.263; 0.119 0.251; 0.120 0.245. O-F
  

  assign(paste0("boost_chain_", i,"_windows", sep=""), boost_chain)
  
  set.seed(717)
  temp_pd_impute_chain_b = partial(object = boost_chain,
                         train = temp[sample(1:nrow(temp), replace = TRUE), ],
                         pred.var = "quarter_num",
                         n.trees = 2500,
                         pred.grid = data.frame(quarter_num = min(temp$quarter_num):max(temp$quarter_num)))
  
  assign(paste0("impute_chain_", i,"_windows", sep=""), temp_pd_impute_chain_b)

  #set.seed(717)
  #pred_q_class = data.frame(quarter_num = c(rep(1,8),  rep(2,8)), PROP_CLA = c("APARTMENT", "PLEX", "FLAT", "GROUP HOUSE", "HOME UNIT", "HOUSE", "TOWN HOUSE", "VILLA HOUSE"))
  #temp_pd_impute_chain = partial(object = randforest_chain,
  #                       train = temp[sample(1:nrow(temp), replace = TRUE), ],
  #                       pred.var = c("quarter_num", "PROP_CLA"),
  #                       n.trees = 2500,
  #                       pred.grid = pred_q_class)
  #set.seed(717)
  #pred_q_lga = data.frame(quarter_num = c(rep(1,30), rep(2,30)), LA_DESC = c("ARMADALE                 ", "BASSENDEAN               ", "BAYSWATER                ", "BELMONT                  ", "CAMBRIDGE                 ", "CANNING                  ", "CLAREMONT                ", "COCKBURN                 ", "COTTESLOE                 ", "EAST FREMANTLE           ", "FREMANTLE                ", "GOSNELLS                 ", "JOONDALUP                ", "KALAMUNDA                ", "KWINANA                  ", "MELVILLE                 ", "MOSMAN PARK              ", "MUNDARING                ", "NEDLANDS                 ", "PEPPERMINT GROVE         ", "PERTH CITY COUNCIL       ", "ROCKINGHAM               ", "SERPENTINE-JARRAHDALE    ", "SOUTH PERTH              ", "STIRLING                 ", "SUBIACO                  ", "SWAN                     ", "VICTORIA PARK            ", "VINCENT                  ", "WANNEROO                 "))
  #temp_pd_impute_chain_b = partial(object = boost_chain,
  #                       train = temp[sample(1:nrow(temp), replace = TRUE), ],
  #                       pred.var = c("quarter_num", "LA_DESC"),
  #                       n.trees = 2500,
  #                       pred.grid = pred_q_lga)
  
  print(i)
}
```


#chained index accuracy
```{r}
for (i in 1:128) {
  temp = model_expert[which(model_expert$quarter_num == i | model_expert$quarter_num == i+1),]

  set.seed(717)
  temp_list = createDataPartition(temp$X, p = 0.8)
  temp_model = temp[temp_list$Resample1,]
  temp_model_test = temp[-temp_list$Resample1,]
  
  boost_chain = get(paste0("boost_chain_", i,"_windows", sep=""))
  temp = predict(boost_chain, temp_model_test, n.tree = 2500)
  
  print(RMSE(temp, temp_model_test$logprice))
  print(RMSE(boost_chain$fit, temp_model$logprice))
}
```


#chain index construct
```{r}
temp_pd_impute_chain_index = data.frame()
temp_pd_impute_chain_index[94,1] = 94
temp_pd_impute_chain_index[94,2] = 1
temp_pd_impute_chain_index[94,3] = 1
for (i in 1:35) {
  temp_pd_impute_chain_b = get(paste0("impute_chain_", i+93,"_windows", sep=""))
  temp_pd_impute_chain_index[i+94,1] = i+94
  temp_pd_impute_chain_index[i+94,2] = exp(temp_pd_impute_chain_b$yhat[2] - temp_pd_impute_chain_b$yhat[1])
  temp_pd_impute_chain_index[i+94,3] = prod(temp_pd_impute_chain_index$V2[94:(94+i)])
}
for (i in 1:93) {
  temp_pd_impute_chain_b = get(paste0("impute_chain_", 94-i,"_windows", sep=""))
  temp_pd_impute_chain_index[94-i,1] = 94-i
  temp_pd_impute_chain_index[94-i,2] = exp(temp_pd_impute_chain_b$yhat[2] - temp_pd_impute_chain_b$yhat[1])
  temp_pd_impute_chain_index[94-i,3] = 1/prod(temp_pd_impute_chain_index$V2[(94-i):94])
}
colnames(temp_pd_impute_chain_index) = c("quarter_num", "diff_qtoq", "index")
```


#seasonal effect
```{r}
impute_index = data.frame(temp_pd_impute_b$quarter_num, temp_pd_impute_b$exp_diff, temp_pd_impute_chain_index$index, abs$index)
colnames(impute_index) = c("quarter", "Pooled_Index", "Chained_Index", "ABS_Index")

impute_index$obs_no = 0
for (i in 1:129) {
  impute_index$obs_no[i] = length(which(model_expert$quarter_num == i))
}
#loess
seasonal_flat = loess(Chained_Index ~ quarter, data = impute_index, weights = obs_no, span = 0.1)
impute_index$flat_chain = predict(seasonal_flat)

seasonal_flat = loess(Pooled_Index ~ quarter, data = impute_index,  weights = obs_no, span = 0.1)
impute_index$flat_pool = predict(seasonal_flat)
```



#show index plots
```{r}
impute_index = data.frame(temp_pd_impute_b$quarter_num, temp_pd_impute_b$exp_diff, temp_pd_impute_chain_index$index, abs$index)
colnames(impute_index) = c("quarter", "Pooled_Index", "Chained_Index", "ABS_Index")

impute_index = impute_index[61:129,-5] %>%
  gather(indextype, index, -quarter)

index_plot = ggplot(impute_index, aes(quarter, index, color = indextype))+geom_line()

ggplotly(index_plot)
```



#model tune
```{r}
hyper_grid = expand.grid(
  shrinkage = c(0.01, 0.1),
  interaction.depth = c(2, 4, 6, 8, 10, 14),
  n.minobsinnode = c(5, 10),
  bag.fraction = c(0.6, 0.8, 1), 
  optimal_trees = 0,               # a place to dump results
  min_RMSE = 0                     # a place to dump results
)

for(i in 1:nrow(hyper_grid)) {
  
  # reproducibility
  set.seed(717)
  
  # train model
  boost_tune = gbm(
    formula = logprice ~ quarter_num + LAND_ARE + AREA_HSE + YEAR_BUI + BEDS + BATHS + numrooms + cars + LA_DESC + PROP_CLA + centlong + centlat + d_strata + d_pool,
    distribution = "gaussian",
    data = temp_boost,
    n.trees = 1000,
    interaction.depth = hyper_grid$interaction.depth[i],
    shrinkage = hyper_grid$shrinkage[i],
    n.minobsinnode = hyper_grid$n.minobsinnode[i],
    bag.fraction = hyper_grid$bag.fraction[i],
    train.fraction = 0.8,
  )
  
  # add min training error and trees to grid
  hyper_grid$optimal_trees[i] = which.min(gbm.tune$valid.error)
  hyper_grid$min_RMSE[i] = sqrt(min(gbm.tune$valid.error))
}

hyper_grid %>% 
  dplyr::arrange(min_RMSE) %>%
  head(10)
```


#regression tree test
```{r}
tree_test = rpart(logprice ~ quarter_num + LAND_ARE + AREA_HSE + YEAR_BUI + BEDS + BATHS + numrooms + cars + LA_DESC + PROP_CLA + centlong + centlat + d_strata + d_pool, data = temp_boost, method = "anova", control = list(minsplit = 5, maxdepth = 60, cp = 0.00001))

set.seed(717)
temp_pd_impute_tree = partial(object = tree_test,
                              train = temp_boost[sample(1:nrow(temp_boost), replace = TRUE), ],
                              pred.var = "quarter_num",
                              pred.grid = data.frame(quarter_num = 1:max(temp_boost$quarter_num)))

RMSE(predict(tree_test, temp_boost_test), temp_boost_test$logprice)
RMSE(predict(tree_test, temp_boost), temp_boost$logprice)
```












































###################################################################
###################################################################
#####################               ###############################
#####################  Test,No use  ###############################
#####################               ###############################
###################################################################
###################################################################
#prepareation
```{r}
nonstrata$quarter = quarter(nonstrata$DATE1)
nonstrata$year = year(nonstrata$DATE1)
nonstrata$quarter_num = (nonstrata$year - 1988)*4 + nonstrata$quarter - 2

nonstrata$d_pool = 0
nonstrata$d_pool[which(nonstrata$POOL == "A/G  " | nonstrata$POOL == "B/G  ")] = 1
```


#model_test  isolation forest; gbm; full window
```{r}
model_test_iso = nonstrata[which(nonstrata$anomaly_if == 0),]
model_test_iso = model_test_iso %>%
  filter(model_test_iso$quarter_num > 0)
#model_test_iso = model_test_iso %>%
#  filter(model_test_iso$LAND_ARE <= 40000)

set.seed(717)
temp_list = createDataPartition(model_test_iso$X, p = 0.8)
temp_model = model_test_iso[temp_list$Resample1,]
temp_model_test = model_test_iso[-temp_list$Resample1,]


set.seed(717)
temp_boost = temp_model
temp_boost$LA_DESC = as.factor(temp_boost$LA_DESC)
temp_boost$PROP_CLA = as.factor(temp_boost$PROP_CLA)
temp_boost_test = temp_model_test
temp_boost_test$LA_DESC = as.factor(temp_boost_test$LA_DESC)
temp_boost_test$PROP_CLA = as.factor(temp_boost_test$PROP_CLA)

boost_test = gbm(logprice ~ quarter_num + LAND_ARE + AREA_HSE + YEAR_BUI + BEDS + BATHS + numrooms + cars + d_pool + LA_DESC + PROP_CLA, data = temp_boost, distribution = "gaussian", n.trees = 1000, interaction.depth = 12, shrinkage = 0.1)

prediction_iso = predict(boost_test, temp_boost_test, n.trees = 1000)
RMSE(prediction_iso, temp_boost_test$logprice)



#landsize <=40000
model_test_iso = nonstrata[which(nonstrata$anomaly_if == 0),]
model_test_iso = model_test_iso %>%
  filter(model_test_iso$quarter_num > 0)
model_test_iso = model_test_iso %>%
  filter(model_test_iso$LAND_ARE <= 40000)

set.seed(717)
temp_list = createDataPartition(model_test_iso$X, p = 0.8)
temp_model = model_test_iso[temp_list$Resample1,]
temp_model_test = model_test_iso[-temp_list$Resample1,]


set.seed(717)
temp_boost = temp_model
temp_boost$LA_DESC = as.factor(temp_boost$LA_DESC)
temp_boost$PROP_CLA = as.factor(temp_boost$PROP_CLA)
temp_boost_test = temp_model_test
temp_boost_test$LA_DESC = as.factor(temp_boost_test$LA_DESC)
temp_boost_test$PROP_CLA = as.factor(temp_boost_test$PROP_CLA)

boost_test_iso = gbm(logprice ~ quarter_num + LAND_ARE + AREA_HSE + YEAR_BUI + BEDS + BATHS + numrooms + cars + d_pool + LA_DESC + PROP_CLA, data = temp_boost, distribution = "gaussian", n.trees = 1000, interaction.depth = 12, shrinkage = 0.1)

prediction_iso = predict(boost_test_iso, temp_boost_test, n.trees = 1000)
RMSE(prediction_iso, temp_boost_test$logprice)
```


#model_test  mahalanobis distance; gbm; full window
```{r}
model_test_md = nonstrata[which(nonstrata$anomaly_md == 0),]
model_test_md = model_test_md %>%
  filter(model_test_md$quarter_num > 0)

set.seed(717)
temp_list = createDataPartition(model_test_md$X, p = 0.8)
temp_model = model_test_md[temp_list$Resample1,]
temp_model_test = model_test_md[-temp_list$Resample1,]


set.seed(717)
temp_boost = temp_model
temp_boost$LA_DESC = as.factor(temp_boost$LA_DESC)
temp_boost$PROP_CLA = as.factor(temp_boost$PROP_CLA)
temp_boost_test = temp_model_test
temp_boost_test$LA_DESC = as.factor(temp_boost_test$LA_DESC)
temp_boost_test$PROP_CLA = as.factor(temp_boost_test$PROP_CLA)

boost_test_md = gbm(logprice ~ quarter_num + LAND_ARE + AREA_HSE + YEAR_BUI + BEDS + BATHS + numrooms + cars + d_pool + LA_DESC + PROP_CLA, data = temp_boost, distribution = "gaussian", n.trees = 1000, interaction.depth = 12, shrinkage = 0.1)

prediction_md = predict(boost_test_md, temp_boost_test, n.trees = 1000)
RMSE(prediction_md, temp_boost_test$logprice)
```


#zscore preparation
```{r}
nonstrata$zscore_price = 0
nonstrata$anomaly_z_price = 1
for (i in 1988:2020) {
  temp = nonstrata %>%
    filter(year(nonstrata$DATE1) == i)

  nonstrata$zscore_price[which(year(nonstrata$DATE1) == i)] = (temp$logprice - mean(temp$logprice))/sd(temp$logprice)
}
nonstrata$anomaly_z_price[which(nonstrata$zscore_price<=4.5 & nonstrata$zscore_price>=-4.5)] = 0
```


#model_test  zscore; gbm; full window
```{r}
model_test_z = nonstrata[which(nonstrata$anomaly_z == 0 & nonstrata$anomaly_z_price == 0),]
model_test_z = model_test_z %>%
  filter(model_test_z$quarter_num > 0)

set.seed(717)
temp_list = createDataPartition(model_test_z$X, p = 0.8)
temp_model = model_test_z[temp_list$Resample1,]
temp_model_test = model_test_z[-temp_list$Resample1,]


set.seed(717)
temp_boost = temp_model
temp_boost$LA_DESC = as.factor(temp_boost$LA_DESC)
temp_boost$PROP_CLA = as.factor(temp_boost$PROP_CLA)
temp_boost_test = temp_model_test
temp_boost_test$LA_DESC = as.factor(temp_boost_test$LA_DESC)
temp_boost_test$PROP_CLA = as.factor(temp_boost_test$PROP_CLA)

boost_test_z = gbm(logprice ~ quarter_num + LAND_ARE + AREA_HSE + YEAR_BUI + BEDS + BATHS + numrooms + cars + d_pool + LA_DESC + PROP_CLA, data = temp_boost, distribution = "gaussian", n.trees = 1000, interaction.depth = 12, shrinkage = 0.1)

prediction_z = predict(boost_test_z, temp_boost_test, n.trees = 1000)
RMSE(prediction_z, temp_boost_test$logprice)
```



#cross-section :iso
```{r}
model_test_iso = nonstrata[which(nonstrata$anomaly_if == 0),]
model_test_iso = model_test_iso %>%
  filter(model_test_iso$quarter_num > 0)

set.seed(717)
temp_list = createDataPartition(model_test_iso$X, p = 0.8)
temp_model = model_test_iso[temp_list$Resample1,]
temp_model_test = model_test_iso[-temp_list$Resample1,]


set.seed(717)
temp_boost = temp_model
temp_boost$LA_DESC = as.factor(temp_boost$LA_DESC)
temp_boost$PROP_CLA = as.factor(temp_boost$PROP_CLA)
temp_boost_test = temp_model_test
temp_boost_test$LA_DESC = as.factor(temp_boost_test$LA_DESC)
temp_boost_test$PROP_CLA = as.factor(temp_boost_test$PROP_CLA)
 
for(i in 1:129){
  set.seed(717)
  temp = temp_boost[which(temp_boost$quarter_num == i),]

  boost = gbm(logprice ~ LAND_ARE + AREA_HSE + YEAR_BUI + BEDS + BATHS + numrooms + cars + d_pool + LA_DESC + PROP_CLA, data = temp, distribution = "gaussian", n.trees = 1000, interaction.depth = 12, shrinkage = 0.1)
  
  assign(paste0("boost_", i, "_iso", sep = ""), boost)
  print(i)
}
```



#cross-section: md
```{r}
model_test_md = nonstrata[which(nonstrata$anomaly_md == 0),]
model_test_md = model_test_md %>%
  filter(model_test_md$quarter_num > 0)

set.seed(717)
temp_list = createDataPartition(model_test_md$X, p = 0.8)
temp_model = model_test_md[temp_list$Resample1,]
temp_model_test = model_test_md[-temp_list$Resample1,]


set.seed(717)
temp_boost = temp_model
temp_boost$LA_DESC = as.factor(temp_boost$LA_DESC)
temp_boost$PROP_CLA = as.factor(temp_boost$PROP_CLA)
temp_boost_test = temp_model_test
temp_boost_test$LA_DESC = as.factor(temp_boost_test$LA_DESC)
temp_boost_test$PROP_CLA = as.factor(temp_boost_test$PROP_CLA)
 
for(i in 1:129){
  set.seed(717)
  temp = temp_boost[which(temp_boost$quarter_num == i),]

  boost = gbm(logprice ~ LAND_ARE + AREA_HSE + YEAR_BUI + BEDS + BATHS + numrooms + cars + d_pool + LA_DESC + PROP_CLA, data = temp, distribution = "gaussian", n.trees = 1000, interaction.depth = 12, shrinkage = 0.1)
  
  assign(paste0("boost_", i, "_md", sep = ""), boost)
  print(i)
}
```



#cross-section: z
```{r}
model_test_z = nonstrata[which(nonstrata$anomaly_z == 0 & nonstrata$anomaly_z_price == 0),]
model_test_z = model_test_z %>%
  filter(model_test_z$quarter_num > 0)

set.seed(717)
temp_list = createDataPartition(model_test_z$X, p = 0.8)
temp_model = model_test_z[temp_list$Resample1,]
temp_model_test = model_test_z[-temp_list$Resample1,]


set.seed(717)
temp_boost = temp_model
temp_boost$LA_DESC = as.factor(temp_boost$LA_DESC)
temp_boost$PROP_CLA = as.factor(temp_boost$PROP_CLA)
temp_boost_test = temp_model_test
temp_boost_test$LA_DESC = as.factor(temp_boost_test$LA_DESC)
temp_boost_test$PROP_CLA = as.factor(temp_boost_test$PROP_CLA)
 
for(i in 1:129){
  set.seed(717)
  temp = temp_boost[which(temp_boost$quarter_num == i),]

  boost = gbm(logprice ~ LAND_ARE + AREA_HSE + YEAR_BUI + BEDS + BATHS + numrooms + cars + d_pool + LA_DESC + PROP_CLA, data = temp, distribution = "gaussian", n.trees = 1000, interaction.depth = 12, shrinkage = 0.1)
  
  assign(paste0("boost_", i, "_z", sep = ""), boost)
  print(i)
}
```


#boost iso
```{r}
temp_rmse = data.frame() 
for(i in 1:129){
  boost = get(paste0("boost_", i, "_iso", sep=""))
  
  temp_rmse[i,1] = RMSE(boost$fit, boost$data$y)
  temp_rmse[i,2] = "Isolation Forest"
  temp_rmse[i,3] = i
}
for(i in 1:129){
  boost = get(paste0("boost_", i, "_md", sep=""))
  
  temp_rmse[i+129,1] = RMSE(boost$fit, boost$data$y)
  temp_rmse[i+129,2] = "Mahalanobis Distance"
  temp_rmse[i+129,3] = i
}
for(i in 1:129){
  boost = get(paste0("boost_", i, "_z", sep=""))
  
  temp_rmse[i+258,1] = RMSE(boost$fit, boost$data$y)
  temp_rmse[i+258,2] = "Zscore"
  temp_rmse[i+258,3] = i
}
colnames(temp_rmse) = c("RMSE", "Method", "Quarter")


ggplot(temp_rmse, aes(Quarter, RMSE, color = Method)) + geom_line()
```

